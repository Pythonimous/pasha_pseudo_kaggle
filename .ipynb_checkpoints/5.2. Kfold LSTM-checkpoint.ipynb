{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wh8lKgPquue4",
    "outputId": "17456124-286c-4337-86ae-86a4ced9c8ff"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf1647b42bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VDgYobyOux8d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/My Drive/lab_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VxprEeG8A9lQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hFOOnKnTSMi8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nc-xtKRaqICk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import train_dev_test, plot_train_acc, plot_train_loss, classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LwBwyRDvgR6w"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_non_lemmatized.csv')\n",
    "test = pd.read_csv('data/test_non_lemmatized.csv')\n",
    "train_features = pd.read_csv('preproc_files/train_features_16.csv')\n",
    "test_features = pd.read_csv('preproc_files/test_features_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BRX4tsGtpfp4"
   },
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X_f = normalize(train_features)\n",
    "X_test_f = normalize(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "odgfNJLhgk3T"
   },
   "outputs": [],
   "source": [
    "# Сколько максимум слов из словаря нам юзать\n",
    "dict_size = 20000\n",
    "# Ограничимся 300 словами\n",
    "max_words = 300\n",
    "# Пусть размерность эмбеддинга будет 200\n",
    "embed_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Cov40GpHgl_Y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "irohHrGsgm_r"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=dict_size, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XZ_2JhwagoOM",
    "outputId": "f89c3ad0-fcc5-4922-afc9-d59056d55fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352514 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(train['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yIos4ajEgpJz",
    "outputId": "553aa498-9d88-44a9-d423-943cd26e9cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (48000, 300)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(train['text'].values)\n",
    "X = pad_sequences(X, maxlen=max_words)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XFG9RRbRgrlc"
   },
   "outputs": [],
   "source": [
    "X_train_e, X_val_e, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BaqkmG49pk8G"
   },
   "outputs": [],
   "source": [
    "X_train_f, X_val_f, _, _ = train_test_split(X_f, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZqhp_L8uptX"
   },
   "source": [
    "#### Pretrained block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BB4OsSwNuve2"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE =  'embeddings/glove.twitter.27B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2_cCfG8B4i6e"
   },
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file == 'embeddings/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "asZ1Ad9suwzh"
   },
   "outputs": [],
   "source": [
    "embeddings_index = load_embed(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "1M85nrpZuyR0",
    "outputId": "63e1727e-70a3-421c-8496-c90fd0351bdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pythonimous/venv/data-science/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3254: FutureWarning:\n",
      "\n",
      "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(dict_size, len(word_index))+1\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= dict_size: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmMQ6RN9utKc"
   },
   "source": [
    "#### Model block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8AKDnMdygsqJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, regularizers, optimizers\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, SpatialDropout1D, LSTM, Dense, BatchNormalization, Dropout, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AsP6RlIHgt3j"
   },
   "outputs": [],
   "source": [
    "def multimodal_lstm(max_words=max_words, misc_input_length=16,\n",
    "                    dict_size=nb_words, embed_dim=200, num_classes=3):\n",
    "    #Define inputs\n",
    "    emb_input = Input(shape=(max_words,), name='post_body_input')\n",
    "    misc_input = Input(shape=(misc_input_length), name='misc_features_input')\n",
    "\n",
    "    # Embedding branch\n",
    "    x_e = Embedding(input_dim=dict_size,\n",
    "                    output_dim=embed_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_words,  # X.shape[1]\n",
    "                    trainable=False,\n",
    "                    name='post_body_embedding')(emb_input)\n",
    "    x_e = SpatialDropout1D(0.5)(x_e)\n",
    "    x_e = Bidirectional(LSTM(units=64,\n",
    "                             return_sequences=True))(x_e)\n",
    "    x_e = Bidirectional(LSTM(units=64))(x_e)\n",
    "    x_e = Model(inputs=emb_input, outputs=x_e)\n",
    "\n",
    "    combined = Concatenate()([x_e.output, misc_input])\n",
    "\n",
    "    z = Dense(num_classes, activation='softmax')(combined)\n",
    "\n",
    "    model = Model(inputs=[x_e.input, misc_input], outputs=z)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rowgGjy_gzDO"
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=20, min_delta=0.0001)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.4, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FlDJB-ZO8HC"
   },
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GXDxczMdO6tT"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_TcBzgKLfMkh"
   },
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "fcKfa31wO78g"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "epochs = 100\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "num_folds = 10 #number of folds\n",
    "\n",
    "predict = np.zeros((X_test.shape[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь гугл колаб меня выкинул на девятом шаге, так что я пытался завершить локально. Если убрать следующую ячейку и if-else в цикле, то всё получается нормально. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4LCEFdUJwssN"
   },
   "outputs": [],
   "source": [
    "with open('results/predict_7_69.pickle', 'rb') as p:\n",
    "    predict = pickle.load(p)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BWeDEMeDPs5I"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=69)  # nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M7Pt5QJfQs3u",
    "outputId": "9a8f715c-81e7-4a15-dc8f-c73bdaeb301a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Fold 8 ------\n",
      "WARNING:tensorflow:From /home/pythonimous/venv/data-science/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/pythonimous/venv/data-science/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/pythonimous/venv/data-science/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/pythonimous/venv/data-science/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/pythonimous/venv/data-science/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "WARNING:tensorflow:From /home/pythonimous/venv/data-science/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      " 2048/43200 [>.............................] - ETA: 4:49 - loss: 1.0865 - acc: 0.3931"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b8809bfe6711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkfold_X_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold_X_valid_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold_y_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 callbacks=[mc, earlystop, lr_reduction])\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/data-science/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/venv/data-science/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/data-science/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/venv/data-science/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    if num < 8:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "            \n",
    "        print(f' Fold {num} '.center(20, '-'))\n",
    "\n",
    "        kfold_y_train, kfold_y_valid = y[train_index], y[test_index]\n",
    "        kfold_X_train = X[train_index]\n",
    "        kfold_X_features = X_f[train_index]\n",
    "        kfold_X_valid = X[test_index]\n",
    "        kfold_X_valid_features = X_f[test_index] \n",
    "        \n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        \n",
    "        model = multimodal_lstm()\n",
    "\n",
    "        mc = ModelCheckpoint(f\"checkpoints/kfold_{num}_lstm.h5\", monitor='val_loss', mode='auto', save_best_only=True)\n",
    "\n",
    "        model.fit([kfold_X_train, kfold_X_features], kfold_y_train,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=([kfold_X_valid, kfold_X_valid_features], kfold_y_valid),\n",
    "                epochs=epochs,\n",
    "                callbacks=[mc, earlystop, lr_reduction])\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "        model.load_weights(f\"checkpoints/kfold_{num}_lstm.h5\")\n",
    "\n",
    "        predict += model.predict([X_test, X_test_f], batch_size=batch_size, verbose=1) / num_folds\n",
    "\n",
    "        with open(f'results/predict_{num}.pickle', 'wb') as p:\n",
    "            pickle.dump(predict, p)\n",
    "        p.close()\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nijSXxjNlidM"
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(p) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2uYNnD4mDI9"
   },
   "outputs": [],
   "source": [
    "from utils import classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEKLsl0MmK7N"
   },
   "outputs": [],
   "source": [
    "classifier_out(predictions, '18.combined_lstm_small_glove_noval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие резы были получены при train-test-split на 420 random state. Я пробовал посылать 69, 420 и среднее между 69 и 420, и лучшие резы были у 420."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_1_5_lstm_kfold (0).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
