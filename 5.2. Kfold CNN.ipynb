{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последнее, что я пытался сделать, когда узнал, что народ выбил дикие резы с помощью CNN - дотюнить в последние два часа. Спустя полтора дня без сна я плохо помню, что именно и как я делал, но помню, что у меня уже не было времени на нормальный грид серч (который я производил с другими моделями), так что я интуитивно менял параметры и пробовал к-фолд посмотреть, выйдет ли хоть ЧТО-ТО за 90% (спойлер - не вышло)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wh8lKgPquue4",
    "outputId": "5fe7dc09-76ae-4ef7-9b68-c647ef6bfb6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDgYobyOux8d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/My Drive/lab_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxprEeG8A9lQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFOOnKnTSMi8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nc-xtKRaqICk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import train_dev_test, plot_train_acc, plot_train_loss, classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwBwyRDvgR6w"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_non_lemmatized.csv')\n",
    "test = pd.read_csv('data/test_non_lemmatized.csv')\n",
    "train_features = pd.read_csv('preproc_files/train_features_16.csv')\n",
    "test_features = pd.read_csv('preproc_files/test_features_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRX4tsGtpfp4"
   },
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X_f = normalize(train_features)\n",
    "X_test_f = normalize(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odgfNJLhgk3T"
   },
   "outputs": [],
   "source": [
    "# Сколько максимум слов из словаря нам юзать\n",
    "dict_size = 100000\n",
    "# Ограничимся 300 словами\n",
    "max_words = 300\n",
    "# Пусть размерность эмбеддинга будет 200\n",
    "embed_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cov40GpHgl_Y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irohHrGsgm_r"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=dict_size, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XZ_2JhwagoOM",
    "outputId": "66feb38a-afe0-4a9e-bf78-93c0a3f4a1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352514 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(train['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yIos4ajEgpJz",
    "outputId": "9070313c-1c0b-44ca-89d4-247931153178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (48000, 300)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(train['text'].values)\n",
    "X = pad_sequences(X, maxlen=max_words)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFG9RRbRgrlc"
   },
   "outputs": [],
   "source": [
    "X_train_e, X_val_e, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaqkmG49pk8G"
   },
   "outputs": [],
   "source": [
    "X_train_f, X_val_f, _, _ = train_test_split(X_f, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZqhp_L8uptX"
   },
   "source": [
    "#### Pretrained block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB4OsSwNuve2"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE =  'embeddings/wiki-news-300d-1M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_cCfG8B4i6e"
   },
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file == 'embeddings/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asZ1Ad9suwzh"
   },
   "outputs": [],
   "source": [
    "embeddings_index = load_embed(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "1M85nrpZuyR0",
    "outputId": "a7f11ec5-64a6-4a7f-d85e-2af24a23a86b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning:\n",
      "\n",
      "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(dict_size, len(word_index))+1\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= dict_size: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmMQ6RN9utKc"
   },
   "source": [
    "#### Model block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AKDnMdygsqJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, regularizers, optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Input, Embedding, Reshape, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-mI5HUmNT6X"
   },
   "outputs": [],
   "source": [
    "num_filters = 64 \n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsP6RlIHgt3j"
   },
   "outputs": [],
   "source": [
    "def lang_cnn(max_words=max_words, misc_input_length=16,\n",
    "                    dict_size=nb_words, embed_dim=300, num_classes=3):\n",
    "    \n",
    "    filter_sizes = [1,2,3]\n",
    "    num_filters = 36\n",
    "    #Define inputs\n",
    "    emb_input = Input(shape=(max_words,), name='post_body_input')\n",
    "  #  misc_input = Input(shape=(misc_input_length), name='misc_features_input')\n",
    "\n",
    "    # Embedding branch\n",
    "    embedding = Embedding(input_dim=dict_size,\n",
    "                    output_dim=embed_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_words,  # X.shape[1]\n",
    "                    trainable=False,\n",
    "                    name='post_body_embedding')(emb_input)\n",
    "\n",
    "    \n",
    "    x = Conv1D(num_filters, 7, activation='relu', padding='same')(embedding)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(num_filters, 7, activation='relu', padding='same')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "   # combined = Concatenate()([x.output, misc_input])\n",
    "\n",
    "    #outputs = Dense(3, activation='softmax')(combined)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model = Model(emb_input, outputs)\n",
    "    #model = Model([x.input, misc_input], outputs)\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "nFA8B8ZWUc7x",
    "outputId": "ad87de02-d621-4ef8-cbd7-2b3dbd9c5fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "post_body_input (InputLayer) [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "post_body_embedding (Embeddi (None, 300, 300)          30000300  \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 300, 36)           75636     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 150, 36)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 150, 36)           9108      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1184      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,086,327\n",
      "Trainable params: 86,027\n",
      "Non-trainable params: 30,000,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lang_cnn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rowgGjy_gzDO"
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.4, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FlDJB-ZO8HC"
   },
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXDxczMdO6tT"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TcBzgKLfMkh"
   },
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcKfa31wO78g"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "epochs = 100\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "num_folds = 5 #number of folds\n",
    "\n",
    "predict = np.zeros((X_test.shape[0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWeDEMeDPs5I"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=777)  # tri_topora!\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M7Pt5QJfQs3u",
    "outputId": "07af5f70-4c17-4e9b-a973-aa15ea3f1b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Fold 0 ------\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 7s 89ms/step - loss: 0.8605 - accuracy: 0.5721 - val_loss: 0.5258 - val_accuracy: 0.7664\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 6s 83ms/step - loss: 0.5073 - accuracy: 0.7814 - val_loss: 0.3888 - val_accuracy: 0.8356\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 6s 82ms/step - loss: 0.4051 - accuracy: 0.8303 - val_loss: 0.3431 - val_accuracy: 0.8527\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.3527 - accuracy: 0.8517 - val_loss: 0.3267 - val_accuracy: 0.8591\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.3220 - accuracy: 0.8693 - val_loss: 0.3390 - val_accuracy: 0.8469\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 7s 88ms/step - loss: 0.2917 - accuracy: 0.8820 - val_loss: 0.3031 - val_accuracy: 0.8709\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 6s 83ms/step - loss: 0.2692 - accuracy: 0.8922 - val_loss: 0.3012 - val_accuracy: 0.8734\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 6s 83ms/step - loss: 0.2494 - accuracy: 0.9012 - val_loss: 0.3011 - val_accuracy: 0.8756\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.2313 - accuracy: 0.9078 - val_loss: 0.3050 - val_accuracy: 0.8761\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 6s 77ms/step - loss: 0.2112 - accuracy: 0.9166 - val_loss: 0.3097 - val_accuracy: 0.8736\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9237\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.1960 - accuracy: 0.9237 - val_loss: 0.3150 - val_accuracy: 0.8723\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.1671 - accuracy: 0.9370 - val_loss: 0.3188 - val_accuracy: 0.8758\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9427\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.1549 - accuracy: 0.9427 - val_loss: 0.3246 - val_accuracy: 0.8744\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.1456 - accuracy: 0.9464 - val_loss: 0.3254 - val_accuracy: 0.8763\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 6s 76ms/step - loss: 0.1425 - accuracy: 0.9470 - val_loss: 0.3334 - val_accuracy: 0.8734\n",
      "Epoch 16/100\n",
      "19/75 [======>.......................] - ETA: 3s - loss: 0.1362 - accuracy: 0.9507"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-6a45e0975995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_X_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold_y_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             callbacks=[mc, earlystop, lr_reduction])\n\u001b[0m\u001b[1;32m     22\u001b[0m     '''\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f' Fold {num} '.center(20, '-'))\n",
    "\n",
    "    kfold_y_train, kfold_y_valid = y[train_index], y[test_index]\n",
    "    kfold_X_train = X[train_index]\n",
    "    kfold_X_features = X_f[train_index]\n",
    "    kfold_X_valid = X[test_index]\n",
    "    kfold_X_valid_features = X_f[test_index] \n",
    "    \n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = lang_cnn()\n",
    "\n",
    "    mc = ModelCheckpoint(f\"checkpoints/kfold_{num}_cnn.h5\", monitor='val_loss', mode='auto', save_best_only=True)\n",
    "\n",
    "    model.fit(kfold_X_train, kfold_y_train,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(kfold_X_valid, kfold_y_valid),\n",
    "            epochs=epochs,\n",
    "            callbacks=[mc, earlystop, lr_reduction])\n",
    "    '''\n",
    "\n",
    "    model.fit([kfold_X_train, kfold_X_features], kfold_y_train,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=([kfold_X_valid, kfold_X_valid_features], kfold_y_valid),\n",
    "            epochs=epochs,\n",
    "            callbacks=[mc, earlystop, lr_reduction])\n",
    "    '''\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    model.load_weights(f\"checkpoints/kfold_{num}_cnn.h5\")\n",
    "\n",
    "    predict += model.predict(X_test, batch_size=batch_size, verbose=1) / num_folds\n",
    "    #predict += model.predict([X_test, X_test_f], batch_size=batch_size, verbose=1) / num_folds\n",
    "\n",
    "    with open(f'results/predict_{num}.pickle', 'wb') as p:\n",
    "        pickle.dump(predict, p)\n",
    "    p.close()\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nijSXxjNlidM"
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(p) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2uYNnD4mDI9"
   },
   "outputs": [],
   "source": [
    "from utils import classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEKLsl0MmK7N"
   },
   "outputs": [],
   "source": [
    "classifier_out(predictions, '18.combined_lstm_small_glove_noval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbKN3fXup3Pe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of lab_1_5_cnn_kfold (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
