{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это вариация LSTM, которая использовалась для получения одних из топ (~97%) результатов для задачи toxic comment classification. Сама архитектура несложная, но довольно заморочены эмбеддинги (плюс понятно она не 1:1, т к у меня свои ad-hoc фичи)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VxprEeG8A9lQ",
    "outputId": "d4fa7f4c-767f-4567-dd37-b3517316c24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dJihWZTqK9Om",
    "outputId": "3f937db7-9e8f-4529-f734-963fead08608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VvUvzhOjK_Br"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/My Drive/lab_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hFOOnKnTSMi8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nc-xtKRaqICk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import train_dev_test, plot_train_acc, plot_train_loss, classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LwBwyRDvgR6w"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_non_lemmatized.csv')\n",
    "test = pd.read_csv('data/test_non_lemmatized.csv')\n",
    "train_features = pd.read_csv('preproc_files/train_features_16.csv')\n",
    "test_features = pd.read_csv('preproc_files/test_features_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BRX4tsGtpfp4"
   },
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X_f = normalize(train_features)\n",
    "X_test_f = normalize(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "odgfNJLhgk3T"
   },
   "outputs": [],
   "source": [
    "# Покрываем наш словарь целиком\n",
    "dict_size = 352514\n",
    "# Пусть будет 900 слов максимум\n",
    "max_words = 900\n",
    "# Размер twitter-glove эмбеддингов - 500\n",
    "embed_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Cov40GpHgl_Y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "irohHrGsgm_r"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=dict_size, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XZ_2JhwagoOM",
    "outputId": "0366f383-4318-463d-efd3-b85ccaa0d67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352514 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(train['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yIos4ajEgpJz",
    "outputId": "ab293eb3-0a8f-4469-de3d-b6fd796d17f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (48000, 900)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(train['text'].values)\n",
    "X = pad_sequences(X, maxlen=max_words)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XFG9RRbRgrlc"
   },
   "outputs": [],
   "source": [
    "X_train_e, X_val_e, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BaqkmG49pk8G"
   },
   "outputs": [],
   "source": [
    "X_train_f, X_val_f, _, _ = train_test_split(X_f, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZqhp_L8uptX"
   },
   "source": [
    "#### Pretrained block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь используются комбинированно уже привычные Glove на твиттере и Fasttext эмбеддинги. Сюда можно было бы ещё к каждому слову прикрутить какие-нибудь POS-фичи, или sentiment, или вежливость/невежливость (например, автор добавляет сюда 501 позицию, чтобы фиксировать, капсом слово написано или нет), но к тому моменту я уже очень устал и не стал это делать, так что у меня это просто в ad-hoc фичах как доля таких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BB4OsSwNuve2"
   },
   "outputs": [],
   "source": [
    "glove =  'embeddings/glove.twitter.27B.200d.txt'\n",
    "fasttext = 'embeddings/wiki-news-300d-1M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "asZ1Ad9suwzh"
   },
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file == 'embeddings/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sYppREIF9QZF"
   },
   "outputs": [],
   "source": [
    "embeddings_index_tw = load_embed(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "J5ULx04b9Qh0"
   },
   "outputs": [],
   "source": [
    "embeddings_index_ft = load_embed(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1M85nrpZuyR0"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(dict_size, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эмбеддинг слова \"что-то\" в каждой из моделей: если мы не находим слово в модели, на его позиции в векторе встают позиции слова \"что-то\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Qbhwidqt6zgV"
   },
   "outputs": [],
   "source": [
    "something_tw = embeddings_index_tw.get(\"something\")\n",
    "something_ft = embeddings_index_ft.get(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HfKBHlTm8G2i"
   },
   "outputs": [],
   "source": [
    "something = np.zeros((500,))\n",
    "something[:300,] = something_ft\n",
    "something[300:500,] = something_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3lT-1T0a7ogR"
   },
   "outputs": [],
   "source": [
    "def embed_word(embedding_matrix,i,word):\n",
    "    embedding_vector_ft = embeddings_index_ft.get(word)\n",
    "    if embedding_vector_ft is not None: \n",
    "        embedding_matrix[i,:300] = embedding_vector_ft\n",
    "        embedding_vector_tw = embeddings_index_tw.get(word)\n",
    "        if embedding_vector_tw is not None:\n",
    "            embedding_matrix[i,300:500] = embedding_vector_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y5HrxOBY8Wel"
   },
   "outputs": [],
   "source": [
    "# Fasttext vector is used by itself if there is no glove vector but not the other way around.\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    \n",
    "    if i >= dict_size: continue\n",
    "        \n",
    "    if embeddings_index_ft.get(word) is not None:\n",
    "        embed_word(embedding_matrix,i,word)\n",
    "    else:\n",
    "        if len(word) > 20:\n",
    "            embedding_matrix[i] = something\n",
    "        else:\n",
    "            word2 = word.title()\n",
    "            if embeddings_index_ft.get(word2) is not None:\n",
    "                embed_word(embedding_matrix,i,word2)\n",
    "            else:\n",
    "                word2 = word.upper()\n",
    "                if embeddings_index_ft.get(word2) is not None:\n",
    "                    embed_word(embedding_matrix,i,word2)\n",
    "                else:\n",
    "                    embedding_matrix[i] = something     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmMQ6RN9utKc"
   },
   "source": [
    "#### Model block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8AKDnMdygsqJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, regularizers, optimizers\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, GRU, GlobalMaxPooling1D, GlobalAveragePooling1D,\\\n",
    " Dense, BatchNormalization, Dropout, SpatialDropout1D, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "R6Bs8_4wJcoX"
   },
   "outputs": [],
   "source": [
    "misc_size = X_train_f.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AsP6RlIHgt3j"
   },
   "outputs": [],
   "source": [
    "def multimodal_lstm(max_words=max_words, misc_input_length=misc_size,\n",
    "                    dict_size=nb_words, embed_dim=500,\n",
    "                    dropout_rate=0.2, num_classes=3):\n",
    "    #Define inputs\n",
    "    emb_input = Input(shape=(max_words,), name='post_body_input')\n",
    "    misc_input = Input(shape=(misc_input_length), name='misc_features_input')\n",
    "\n",
    "    # Embedding branch\n",
    "    x_e = Embedding(input_dim=dict_size,\n",
    "                    output_dim=embed_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_words,  # X.shape[1]\n",
    "                    trainable=False,\n",
    "                    name='post_body_embedding')(emb_input)\n",
    "    x_e = SpatialDropout1D(0.5)(x_e)\n",
    "\n",
    "    x_e = Bidirectional(LSTM(units=40,\n",
    "                             return_sequences=True,))(x_e)\n",
    "                             #dropout=0.4,\n",
    "                             #kernel_regularizer=regularizers.l2(0.01)))(x_e)\n",
    "    x_e, state_h, state_c = Bidirectional(GRU(units=40,\n",
    "                                          return_sequences=True,\n",
    "                                          return_state=True))(x_e)\n",
    "                             #dropout=0.2,\n",
    "                             #kernel_regularizer=regularizers.l2(0.01)))(x_e)\n",
    "    maxpool = GlobalMaxPooling1D()(x_e)\n",
    "    avgpool = GlobalAveragePooling1D()(x_e)\n",
    "\n",
    "    x_e = Concatenate()([maxpool, avgpool, state_h])  # maxpool, avgpool, скрытое состояние\n",
    "\n",
    "   # x_e = Dropout(0.5)(x_e)\n",
    "\n",
    "    x_e = Model(inputs=emb_input, outputs=x_e)\n",
    "\n",
    "    z = Concatenate()([x_e.output, misc_input])  # к тем трём ещё наши дополнительные фичи\n",
    "\n",
    "    #z = Dense(256, activation='relu')(z)\n",
    "    #z = BatchNormalization(trainable=True)(z)\n",
    "    #z = Dropout(dropout_rate)(z)\n",
    "    z = Dense(num_classes, activation='softmax')(z)\n",
    "\n",
    "    model = Model(inputs=[x_e.input, misc_input], outputs=z)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "JLtzRJz-dP2H",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b44b0e306cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# gradient clipping на 1 помог улучшить\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(clipvalue=1)  # gradient clipping на 1 помог улучшить, упс, инстинктивно исполнил ячейку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "7E8C5NvAgu3h",
    "outputId": "501f1226-c6d8-4b46-e1ed-29c151c864df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "post_body_input (InputLayer)    [(None, 900)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "post_body_embedding (Embedding) (None, 900, 500)     176257500   post_body_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 900, 500)     0           post_body_embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 900, 80)      173120      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 900, 80), (N 29280       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 80)           0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 80)           0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200)          0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_average_pooling1d[0][0]   \n",
      "                                                                 bidirectional_1[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "misc_features_input (InputLayer [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 216)          0           concatenate[0][0]                \n",
      "                                                                 misc_features_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            651         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 176,460,551\n",
      "Trainable params: 203,051\n",
      "Non-trainable params: 176,257,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = multimodal_lstm()\n",
    "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MONOSVBNgxyv"
   },
   "outputs": [],
   "source": [
    "#epochs = 100\n",
    "epochs = 30\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rowgGjy_gzDO"
   },
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('checkpoints/best_lstm.h5', monitor='val_loss', mode='auto', save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.4, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "psCxKnGog12I",
    "outputId": "363be991-0745-4cab-bf95-a6e4ab58ab68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "85/85 [==============================] - 68s 803ms/step - loss: 0.7312 - accuracy: 0.6718 - val_loss: 0.4375 - val_accuracy: 0.8252\n",
      "Epoch 2/30\n",
      "85/85 [==============================] - 55s 650ms/step - loss: 0.4334 - accuracy: 0.8142 - val_loss: 0.3635 - val_accuracy: 0.8498\n",
      "Epoch 3/30\n",
      "85/85 [==============================] - 55s 648ms/step - loss: 0.3745 - accuracy: 0.8389 - val_loss: 0.3548 - val_accuracy: 0.8475\n",
      "Epoch 4/30\n",
      "85/85 [==============================] - 55s 648ms/step - loss: 0.3470 - accuracy: 0.8517 - val_loss: 0.3278 - val_accuracy: 0.8635\n",
      "Epoch 5/30\n",
      "85/85 [==============================] - 51s 596ms/step - loss: 0.3278 - accuracy: 0.8602 - val_loss: 0.3342 - val_accuracy: 0.8600\n",
      "Epoch 6/30\n",
      "85/85 [==============================] - 55s 645ms/step - loss: 0.3127 - accuracy: 0.8663 - val_loss: 0.3117 - val_accuracy: 0.8696\n",
      "Epoch 7/30\n",
      "85/85 [==============================] - 55s 647ms/step - loss: 0.3008 - accuracy: 0.8731 - val_loss: 0.3091 - val_accuracy: 0.8710\n",
      "Epoch 8/30\n",
      "85/85 [==============================] - 55s 644ms/step - loss: 0.2920 - accuracy: 0.8770 - val_loss: 0.2857 - val_accuracy: 0.8840\n",
      "Epoch 9/30\n",
      "85/85 [==============================] - 55s 646ms/step - loss: 0.2796 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8840\n",
      "Epoch 10/30\n",
      "85/85 [==============================] - 50s 593ms/step - loss: 0.2677 - accuracy: 0.8888 - val_loss: 0.2844 - val_accuracy: 0.8842\n",
      "Epoch 11/30\n",
      "85/85 [==============================] - 50s 590ms/step - loss: 0.2619 - accuracy: 0.8919 - val_loss: 0.3064 - val_accuracy: 0.8702\n",
      "Epoch 12/30\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.8932\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 0.2562 - accuracy: 0.8932 - val_loss: 0.2838 - val_accuracy: 0.8813\n",
      "Epoch 13/30\n",
      "85/85 [==============================] - 55s 641ms/step - loss: 0.2442 - accuracy: 0.9002 - val_loss: 0.2814 - val_accuracy: 0.8825\n",
      "Epoch 14/30\n",
      "85/85 [==============================] - 55s 643ms/step - loss: 0.2394 - accuracy: 0.9025 - val_loss: 0.2749 - val_accuracy: 0.8888\n",
      "Epoch 15/30\n",
      "85/85 [==============================] - 50s 590ms/step - loss: 0.2383 - accuracy: 0.9022 - val_loss: 0.2961 - val_accuracy: 0.8781\n",
      "Epoch 16/30\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9028\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "85/85 [==============================] - 54s 640ms/step - loss: 0.2346 - accuracy: 0.9028 - val_loss: 0.2733 - val_accuracy: 0.8869\n",
      "Epoch 17/30\n",
      "85/85 [==============================] - 50s 592ms/step - loss: 0.2293 - accuracy: 0.9056 - val_loss: 0.2800 - val_accuracy: 0.8850\n",
      "Epoch 18/30\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9068\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 0.2298 - accuracy: 0.9068 - val_loss: 0.2760 - val_accuracy: 0.8881\n",
      "Epoch 19/30\n",
      "85/85 [==============================] - 50s 588ms/step - loss: 0.2284 - accuracy: 0.9068 - val_loss: 0.2774 - val_accuracy: 0.8869\n",
      "Epoch 20/30\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9088\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "85/85 [==============================] - 50s 588ms/step - loss: 0.2233 - accuracy: 0.9088 - val_loss: 0.2769 - val_accuracy: 0.8871\n",
      "Epoch 21/30\n",
      "85/85 [==============================] - 50s 590ms/step - loss: 0.2247 - accuracy: 0.9091 - val_loss: 0.2771 - val_accuracy: 0.8867\n",
      "Epoch 22/30\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9079\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 0.2250 - accuracy: 0.9079 - val_loss: 0.2770 - val_accuracy: 0.8856\n",
      "Epoch 23/30\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 0.2239 - accuracy: 0.9096 - val_loss: 0.2757 - val_accuracy: 0.8869\n",
      "Epoch 24/30\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9089\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 0.2239 - accuracy: 0.9089 - val_loss: 0.2787 - val_accuracy: 0.8854\n",
      "Epoch 25/30\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 0.2248 - accuracy: 0.9089 - val_loss: 0.2768 - val_accuracy: 0.8865\n",
      "Epoch 26/30\n",
      "20/85 [======>.......................] - ETA: 34s - loss: 0.2230 - accuracy: 0.9104"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-26920b949427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                          callbacks=[mc, lr_reduction])\n\u001b[0m\u001b[1;32m      6\u001b[0m                          \u001b[0;31m#callbacks=[mc, earlystop, lr_reduction])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit([X_train_e, X_train_f], y_train,\n",
    "                         batch_size=batch_size,\n",
    "                         validation_data=([X_val_e, X_val_f], y_val),\n",
    "                         epochs=epochs,\n",
    "                         callbacks=[mc, lr_reduction])\n",
    "                         #callbacks=[mc, earlystop, lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HNu-9tRDliVF"
   },
   "outputs": [],
   "source": [
    "lstm_model.load_weights('checkpoints/best_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_TcBzgKLfMkh"
   },
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZRjDg-F7eunU"
   },
   "outputs": [],
   "source": [
    "predictions = lstm_model.predict([X_test, X_test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nijSXxjNlidM"
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(p) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2uYNnD4mDI9"
   },
   "outputs": [],
   "source": [
    "from utils import classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEKLsl0MmK7N"
   },
   "outputs": [],
   "source": [
    "classifier_out(predictions, '20.fucking_retard_v2')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_1_1_lstm_combined_inputs_nopadding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
